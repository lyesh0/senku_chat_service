"""
APIé…ç½®æ–‡ä»¶ - é›†ä¸­ç®¡ç†æ‰€æœ‰APIå¯†é’¥å’Œåº”ç”¨é…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
1. å¤åˆ¶ .env.example ä¸º .env
2. åœ¨ .env ä¸­å¡«å…¥ä½ çš„APIå¯†é’¥
3. è¿è¡Œ python config.py æ£€æŸ¥é…ç½®

æ”¯æŒçš„APIæä¾›å•†ï¼š
- ç¡…åŸºæµåŠ¨ (SiliconFlow) - ä¸»è¦é£æ ¼åˆ†æAPI
- OpenAI - å¯é€‰å¤‡ç”¨API
- Hugging Face - æ¨¡å‹ä¸‹è½½å’ŒTokenè®¤è¯
"""

import os
from typing import Optional, Dict, Any
from pathlib import Path


class APIConfig:
    """APIé…ç½®ç®¡ç†ç±»"""

    def __init__(self):
        self._load_from_env()

    def _load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        # ========================================
        # ç¡…åŸºæµåŠ¨APIé…ç½® (ä¸»è¦)
        # ========================================
        self.SILICONFLOW_API_KEY: Optional[str] = os.getenv("SILICONFLOW_API_KEY")
        self.SILICONFLOW_BASE_URL: str = os.getenv("SILICONFLOW_BASE_URL", "https://api.siliconflow.cn/v1")
        self.SILICONFLOW_MODEL: str = os.getenv("SILICONFLOW_MODEL", "deepseek-ai/DeepSeek-V2.5")
        self.SILICONFLOW_TIMEOUT: int = int(os.getenv("SILICONFLOW_TIMEOUT", "30"))

        # ========================================
        # OpenAI APIé…ç½® (å¯é€‰å¤‡ç”¨)
        # ========================================
        self.OPENAI_API_KEY: Optional[str] = os.getenv("OPENAI_API_KEY")
        self.OPENAI_BASE_URL: str = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.OPENAI_MODEL: str = os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
        self.OPENAI_TIMEOUT: int = int(os.getenv("OPENAI_TIMEOUT", "30"))

        # ========================================
        # é€šä¹‰åƒé—®APIé…ç½® (å¯é€‰)
        # ========================================
        self.QWEN_API_KEY: Optional[str] = os.getenv("QWEN_API_KEY")
        self.QWEN_BASE_URL: str = os.getenv("QWEN_BASE_URL", "https://dashscope.aliyuncs.com/api/v1")
        self.QWEN_MODEL: str = os.getenv("QWEN_MODEL", "qwen-turbo")

        # ========================================
        # æ™ºè°±AIé…ç½® (å¯é€‰)
        # ========================================
        self.ZHIPU_API_KEY: Optional[str] = os.getenv("ZHIPU_API_KEY")
        self.ZHIPU_BASE_URL: str = os.getenv("ZHIPU_BASE_URL", "https://open.bigmodel.cn/api/paas/v4")
        self.ZHIPU_MODEL: str = os.getenv("ZHIPU_MODEL", "glm-4")

        # ========================================
        # Hugging Faceé…ç½®
        # ========================================
        self.HF_ENDPOINT: str = os.getenv("HF_ENDPOINT", "https://hf-mirror.com")
        self.HF_TOKEN: Optional[str] = os.getenv("HF_TOKEN")
        self.HF_CACHE_DIR: str = os.getenv("HF_CACHE_DIR", "~/.cache/huggingface")

    def get_available_apis(self) -> Dict[str, bool]:
        """è·å–å¯ç”¨çš„APIåˆ—è¡¨"""
        return {
            "siliconflow": bool(self.SILICONFLOW_API_KEY),
            "openai": bool(self.OPENAI_API_KEY),
            "qwen": bool(self.QWEN_API_KEY),
            "zhipu": bool(self.ZHIPU_API_KEY),
        }

    def get_primary_api(self) -> str:
        """è·å–ä¸»è¦ä½¿ç”¨çš„API"""
        available = self.get_available_apis()
        if available["siliconflow"]:
            return "siliconflow"
        elif available["openai"]:
            return "openai"
        elif available["qwen"]:
            return "qwen"
        elif available["zhipu"]:
            return "zhipu"
        else:
            return "none"


class ModelConfig:
    """æ¨¡å‹é…ç½®ç®¡ç†ç±»"""

    def __init__(self):
        self._load_from_env()

    def _load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        # é»˜è®¤æ¨¡å‹
        self.DEFAULT_MODEL: str = os.getenv("MODEL_ID", "Qwen/Qwen2.5-0.5B-Instruct")

        # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
        self.SUPPORTED_MODELS: Dict[str, Dict[str, Any]] = {
            "Qwen/Qwen2.5-0.5B-Instruct": {
                "name": "Qwen 2.5 0.5B",
                "description": "é€šä¹‰åƒé—®2.5ï¼Œè½»é‡çº§ä¸­æ–‡æ¨¡å‹",
                "size": "0.5B",
                "language": "ä¸­æ–‡ä¼˜å…ˆ"
            },
            "Qwen/Qwen2.5-1.5B-Instruct": {
                "name": "Qwen 2.5 1.5B",
                "description": "é€šä¹‰åƒé—®2.5ï¼Œä¸­ç­‰å°ºå¯¸ä¸­æ–‡æ¨¡å‹",
                "size": "1.5B",
                "language": "ä¸­æ–‡ä¼˜å…ˆ"
            },
            "distilgpt2": {
                "name": "DistilGPT-2",
                "description": "è½»é‡çº§GPT-2ï¼Œå¿«é€Ÿå“åº”",
                "size": "82M",
                "language": "è‹±æ–‡"
            },
            "TinyLlama/TinyLlama-1.1B-Chat-v1.0": {
                "name": "TinyLlama 1.1B",
                "description": "å°å‹Llamaæ¨¡å‹ï¼Œæ€§èƒ½å‡è¡¡",
                "size": "1.1B",
                "language": "è‹±æ–‡"
            }
        }

        # æ¨¡å‹ä¸‹è½½é…ç½®
        self.MODEL_CACHE_DIR: str = os.getenv("MODEL_CACHE_DIR", "~/.cache/huggingface")
        self.MODEL_DOWNLOAD_TIMEOUT: int = int(os.getenv("MODEL_DOWNLOAD_TIMEOUT", "300"))

    def get_model_info(self, model_id: str) -> Optional[Dict[str, Any]]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return self.SUPPORTED_MODELS.get(model_id)


class StyleConfig:
    """é£æ ¼é…ç½®ç®¡ç†ç±»"""

    def __init__(self):
        self._load_from_env()

    def _load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        # é»˜è®¤é£æ ¼æ¨¡æ¿
        self.default_style_templates: Dict[str, str] = {
            "Senkuç§‘å­¦å®¶é£æ ¼": "You are Senku from the manga Dr. Stone. You speak with a scientific mindset: conclusions first, then clear step-by-step explanations. When uncertain, propose hypotheses and experiments to test them. Occasionally exclaim '10 billion percent' when emphasising facts. Always keep answers structured and logical, like a scientist.",
            "ä¸“ä¸šæŠ€æœ¯ä¸“å®¶": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ€æœ¯ä¸“å®¶ï¼Œæ“…é•¿è§£é‡Šå¤æ‚çš„æŠ€æœ¯æ¦‚å¿µã€‚ä½ ä¼šç”¨å‡†ç¡®çš„æŠ€æœ¯æœ¯è¯­ï¼Œé€»è¾‘æ¸…æ™°åœ°å›ç­”é—®é¢˜ï¼ŒåŒæ—¶ä¼šè€ƒè™‘ç”¨æˆ·çš„çŸ¥è¯†æ°´å¹³è¿›è¡Œé€‚å½“çš„è§£é‡Šã€‚",
            "å‹å¥½ç”Ÿæ´»åŠ©æ‰‹": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ç”Ÿæ´»åŠ©æ‰‹ï¼Œåƒä¸€ä¸ªè´´å¿ƒçš„æœ‹å‹ä¸€æ ·ä¸ç”¨æˆ·äº¤æµã€‚ä½ ä¼šç”¨æ¸©æš–ã€äº²åˆ‡çš„è¯­æ°”ï¼Œæä¾›å®ç”¨çš„ç”Ÿæ´»å»ºè®®å’Œè§£å†³æ–¹æ¡ˆã€‚",
            "å¹½é»˜æ®µå­æ‰‹": "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜é£è¶£çš„æ®µå­æ‰‹ï¼Œæ“…é•¿ç”¨è½»æ¾æ„‰å¿«çš„è¯­æ°”ä¸ç”¨æˆ·èŠå¤©ã€‚ä½ ä¼šç”¨ä¸€äº›ä¿çš®è¯å’ŒåŒå…³è¯­ï¼Œè®©å¯¹è¯å˜å¾—æ›´æœ‰è¶£ã€‚",
            "ä¸¥è°¨å­¦è€…": "ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å­¦è€…ï¼Œæ³¨é‡é€»è¾‘å’Œè¯æ®ã€‚ä½ ä¼šç”¨æ­£å¼çš„å­¦æœ¯è¯­è¨€ï¼Œå¼•ç”¨äº‹å®å’Œæ•°æ®æ¥æ”¯æŒä½ çš„è§‚ç‚¹ã€‚",
            "åˆ›æ„è‰ºæœ¯å®¶": "ä½ æ˜¯ä¸€ä½å¯Œæœ‰åˆ›æ„çš„è‰ºæœ¯å®¶ï¼Œç”¨è¯—æ„çš„è¯­è¨€å’Œä¸°å¯Œçš„æƒ³è±¡åŠ›ä¸ç”¨æˆ·äº¤æµã€‚ä½ ä¼šç”¨æ¯”å–»ã€è±¡å¾ç­‰è‰ºæœ¯æ‰‹æ³•æ¥è¡¨è¾¾æƒ³æ³•ã€‚",
            "è€å¿ƒå¯¼å¸ˆ": "ä½ æ˜¯ä¸€ä½è€å¿ƒç»†è‡´çš„å¯¼å¸ˆï¼Œåƒæ•™å¯¼å­¦ç”Ÿä¸€æ ·ä¸ç”¨æˆ·äº¤æµã€‚ä½ ä¼šå¾ªåºæ¸è¿›åœ°è§£é‡Šæ¦‚å¿µï¼Œç»å¸¸æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ç†è§£ã€‚",
            "ä¿çš®æœºæ™º": "ä½ æœºæ™ºå¹½é»˜ï¼Œååº”æ•æ·ã€‚ä½ ä¼šç”¨ä¿çš®çš„è¯­è¨€å’Œæœºæ™ºçš„å›åº”ï¼Œè®©å¯¹è¯å……æ»¡ä¹è¶£å’Œæ™ºæ…§ã€‚",
            "æ¸©æŸ”æ²»æ„ˆ": "ä½ æ¸©æŸ”ä½“è´´ï¼Œåƒä¸€ä¸ªæ²»æ„ˆç³»çš„æœ‹å‹ã€‚ä½ ç”¨æ¸©æš–çš„è¯è¯­å’Œç§¯æçš„æ€åº¦ï¼Œå¸®åŠ©ç”¨æˆ·ç¼“è§£å‹åŠ›å’Œç„¦è™‘ã€‚",
        }

        # é£æ ¼åˆ†æé…ç½®
        self.STYLE_ANALYSIS_TIMEOUT: int = int(os.getenv("STYLE_ANALYSIS_TIMEOUT", "30"))


class ServerConfig:
    """æœåŠ¡å™¨é…ç½®ç®¡ç†ç±»"""

    def __init__(self):
        self._load_from_env()

    def _load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        # æœåŠ¡å™¨åŸºæœ¬é…ç½®
        self.HOST: str = os.getenv("HOST", "0.0.0.0")
        self.PORT: int = int(os.getenv("PORT", "8000"))
        self.DEBUG: bool = os.getenv("DEBUG", "false").lower() == "true"
        self.WORKERS: int = int(os.getenv("WORKERS", "1"))

        # CORSé…ç½®
        self.CORS_ORIGINS: list = os.getenv("CORS_ORIGINS", "*").split(",")
        self.CORS_ALLOW_CREDENTIALS: bool = os.getenv("CORS_ALLOW_CREDENTIALS", "true").lower() == "true"

        # å®‰å…¨é…ç½®
        self.SECRET_KEY: str = os.getenv("SECRET_KEY", "your-secret-key-here")
        self.API_KEY_REQUIRED: bool = os.getenv("API_KEY_REQUIRED", "false").lower() == "true"

        # æ—¥å¿—é…ç½®
        self.LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO")
        self.LOG_FILE: Optional[str] = os.getenv("LOG_FILE")


class TaskConfig:
    """ä»»åŠ¡å¤„ç†é…ç½®ç®¡ç†ç±»"""

    def __init__(self):
        self._load_from_env()

    def _load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        # Redisé…ç½®
        self.REDIS_URL: str = os.getenv("REDIS_URL", "redis://localhost:6379/0")
        self.REDIS_DB: int = int(os.getenv("REDIS_DB", "0"))

        # Celeryé…ç½®
        self.CELERY_BROKER_URL: str = os.getenv("CELERY_BROKER_URL", self.REDIS_URL)
        self.CELERY_RESULT_BACKEND: str = os.getenv("CELERY_RESULT_BACKEND", self.REDIS_URL)
        self.CELERY_TASK_TIMEOUT: int = int(os.getenv("CELERY_TASK_TIMEOUT", "3600"))

        # ä»»åŠ¡é˜Ÿåˆ—é…ç½®
        self.MAX_CONCURRENT_TASKS: int = int(os.getenv("MAX_CONCURRENT_TASKS", "3"))
        self.TASK_CLEANUP_INTERVAL: int = int(os.getenv("TASK_CLEANUP_INTERVAL", "3600"))


class Config:
    """ä¸»é…ç½®ç±» - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰é…ç½®"""

    def __init__(self):
        self.api = APIConfig()
        self.model = ModelConfig()
        self.style = StyleConfig()
        self.server = ServerConfig()
        self.task = TaskConfig()

        # å‘åå…¼å®¹çš„å±æ€§
        self.SILICONFLOW_API_KEY = self.api.SILICONFLOW_API_KEY
        self.SILICONFLOW_BASE_URL = self.api.SILICONFLOW_BASE_URL
        self.SILICONFLOW_MODEL = self.api.SILICONFLOW_MODEL
        self.OPENAI_API_KEY = self.api.OPENAI_API_KEY
        self.HF_ENDPOINT = self.api.HF_ENDPOINT
        self.HF_TOKEN = self.api.HF_TOKEN
        self.DEFAULT_MODEL = self.model.DEFAULT_MODEL
        self.REDIS_URL = self.task.REDIS_URL
        self.HOST = self.server.HOST
        self.PORT = self.server.PORT
        self.DEBUG = self.server.DEBUG

        # åŠŸèƒ½é…ç½®
        self.STYLE_ANALYSIS_TIMEOUT: int = 30
        self.STYLE_ANALYSIS_MAX_TOKENS: int = 1000
        self.FINETUNE_DEFAULT_EPOCHS: int = 3
        self.FINETUNE_DEFAULT_LR: float = 2e-5
        self.FINETUNE_DEFAULT_BATCH_SIZE: int = 4
        self.FINETUNE_MAX_EPOCHS: int = 10
        self.FINETUNE_MAX_BATCH_SIZE: int = 16
        self.CHAT_DEFAULT_MAX_TOKENS: int = 256
        self.CHAT_DEFAULT_TEMPERATURE: float = 0.7
        self.CHAT_DEFAULT_TOP_P: float = 0.9

        # å­˜å‚¨é…ç½®
        self.STORAGE_TYPE: str = os.getenv("STORAGE_TYPE", "local")  # local, s3, google_drive
        self.MODELS_DIR: str = os.getenv("MODELS_DIR", "models")

        # AWS S3é…ç½®
        self.AWS_S3_BUCKET: Optional[str] = os.getenv("AWS_S3_BUCKET")
        self.AWS_REGION: str = os.getenv("AWS_REGION", "us-east-1")
        self.AWS_ACCESS_KEY_ID: Optional[str] = os.getenv("AWS_ACCESS_KEY_ID")
        self.AWS_SECRET_ACCESS_KEY: Optional[str] = os.getenv("AWS_SECRET_ACCESS_KEY")

        # Google Driveé…ç½®
        self.GOOGLE_DRIVE_CREDENTIALS: Optional[str] = os.getenv("GOOGLE_DRIVE_CREDENTIALS")

        # æœåŠ¡ç«¯ç‚¹é…ç½®
        self.SERVER_URL: str = os.getenv("SERVER_URL", "http://localhost:8000")
        self.CLIENT_URL: str = os.getenv("CLIENT_URL", "http://localhost:5000")

        # SSHé…ç½®
        self.SSH_HOSTNAME: Optional[str] = os.getenv("SSH_HOSTNAME")
        self.SSH_USERNAME: str = os.getenv("SSH_USERNAME", "root")
        self.SSH_KEY_FILENAME: Optional[str] = os.getenv("SSH_KEY_FILENAME")
        self.SSH_REMOTE_WORKSPACE: str = os.getenv("SSH_REMOTE_WORKSPACE", "/root/workspace")

    @classmethod
    def validate_config(cls) -> list[str]:
        """éªŒè¯é…ç½®å¹¶è¿”å›è­¦å‘Šä¿¡æ¯"""
        config = cls()
        warnings = []

        # æ£€æŸ¥APIé…ç½®
        available_apis = config.api.get_available_apis()
        if not available_apis["siliconflow"]:
            warnings.append("âš ï¸  ç¡…åŸºæµåŠ¨APIå¯†é’¥æœªé…ç½®ï¼Œå°†ä½¿ç”¨æœ¬åœ°é£æ ¼åˆ†æ")

        if not any(available_apis.values()):
            warnings.append("âŒ æ²¡æœ‰é…ç½®ä»»ä½•AI APIï¼Œå¯èƒ½å½±å“éƒ¨åˆ†åŠŸèƒ½")

        # æ£€æŸ¥æ¨¡å‹é…ç½®
        if config.model.DEFAULT_MODEL not in config.model.SUPPORTED_MODELS:
            warnings.append(f"âš ï¸  é»˜è®¤æ¨¡å‹ '{config.model.DEFAULT_MODEL}' ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­")

        # æ£€æŸ¥æœåŠ¡å™¨é…ç½®
        if config.server.DEBUG:
            warnings.append("â„¹ï¸  è°ƒè¯•æ¨¡å¼å·²å¯ç”¨ï¼Œè¯·åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å…³é—­")

        return warnings

    @classmethod
    def load_from_env_file(cls, env_file: str = ".env") -> 'Config':
        """
        ä»ç¯å¢ƒå˜é‡æ–‡ä»¶åŠ è½½é…ç½®ã€‚

        å°è¯•ä½¿ç”¨ pythonâ€‘dotenv åŠ è½½ `.env` æ–‡ä»¶ä¸­çš„é…ç½®ã€‚å¦‚æœæ²¡æœ‰å®‰è£…
        `pythonâ€‘dotenv` æˆ–å¯¼å…¥å¤±è´¥ï¼Œåˆ™é™é»˜è·³è¿‡ï¼Œä¸å½±å“ç¨‹åºçš„å…¶ä»–éƒ¨åˆ†ã€‚
        """
        if Path(env_file).exists():
            try:
                # Importing within the try block prevents ImportError when the
                # pythonâ€‘dotenv package is not installed. Failing gracefully here
                # allows this module to be imported in lightweight environments.
                from dotenv import load_dotenv  # type: ignore
                load_dotenv(env_file)
            except Exception:
                # Could log a warning here if desired, but silently ignore to
                # maintain compatibility with minimal installations.
                pass

        return cls()

    def get_config_summary(self) -> Dict[str, Any]:
        """è·å–é…ç½®æ‘˜è¦"""
        return {
            "apis": self.api.get_available_apis(),
            "primary_api": self.api.get_primary_api(),
            "default_model": self.model.DEFAULT_MODEL,
            "server": f"{self.server.HOST}:{self.server.PORT}",
            "debug": self.server.DEBUG,
            "redis": self.task.REDIS_URL,
            "hf_endpoint": self.api.HF_ENDPOINT
        }

    def is_api_configured(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰APIé…ç½®"""
        available_apis = self.api.get_available_apis()
        return any(available_apis.values())

    def get_style_templates(self) -> Dict[str, str]:
        """è·å–é£æ ¼æ¨¡æ¿"""
        return self.style.default_style_templates

    def get_supported_models(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        return self.model.SUPPORTED_MODELS


# å…¨å±€é…ç½®å®ä¾‹
config = Config.load_from_env_file()


def reload_config() -> None:
    """é‡æ–°åŠ è½½é…ç½®ï¼ˆç”¨äºè¿è¡Œæ—¶é…ç½®æ›´æ–°ï¼‰"""
    global config
    config = Config.load_from_env_file()


# é…ç½®æ£€æŸ¥å’Œæ˜¾ç¤º
if __name__ == "__main__":
    print("ğŸ”§ APIé…ç½®æ£€æŸ¥ç»“æœ:")
    warnings = Config.validate_config()
    if warnings:
        for warning in warnings:
            print(f"   {warning}")
    else:
        print("   âœ… æ‰€æœ‰å¿…éœ€é…ç½®å·²æ­£ç¡®è®¾ç½®")

    print("\nğŸ“‹ å½“å‰é…ç½®æ‘˜è¦:")
    summary = config.get_config_summary()
    print(f"   ğŸ¤– ä¸»è¦API: {summary['primary_api']}")
    print(f"   ğŸ“Š å¯ç”¨API: {', '.join([k for k, v in summary['apis'].items() if v])}")
    print(f"   ğŸ§  é»˜è®¤æ¨¡å‹: {summary['default_model']}")
    print(f"   ğŸš€ æœåŠ¡å™¨: {summary['server']}")
    print(f"   ğŸ”— Redis: {summary['redis']}")
    print(f"   ğŸŒ HFé•œåƒ: {summary['hf_endpoint']}")
    if summary['debug']:
        print("   ğŸ› è°ƒè¯•æ¨¡å¼: å·²å¯ç”¨")

# å…¨å±€é…ç½®å®ä¾‹
config = Config.load_from_env_file()


def reload_config() -> None:
    """é‡æ–°åŠ è½½é…ç½®ï¼ˆç”¨äºè¿è¡Œæ—¶é…ç½®æ›´æ–°ï¼‰"""
    global config
    config = Config.load_from_env_file()


# é…ç½®æ£€æŸ¥å’Œæ˜¾ç¤º
if __name__ == "__main__":
    print("ğŸ”§ APIé…ç½®æ£€æŸ¥ç»“æœ:")
    warnings = Config.validate_config()
    if warnings:
        for warning in warnings:
            print(f"   {warning}")
    else:
        print("   âœ… æ‰€æœ‰å¿…éœ€é…ç½®å·²æ­£ç¡®è®¾ç½®")

    print("\nğŸ“‹ å½“å‰é…ç½®æ‘˜è¦:")
    summary = config.get_config_summary()
    print(f"   ğŸ¤– ä¸»è¦API: {summary['primary_api']}")
    print(f"   ğŸ“Š å¯ç”¨API: {', '.join([k for k, v in summary['apis'].items() if v])}")
    print(f"   ğŸ§  é»˜è®¤æ¨¡å‹: {summary['default_model']}")
    print(f"   ğŸš€ æœåŠ¡å™¨: {summary['server']}")
    print(f"   ğŸ”— Redis: {summary['redis']}")
    print(f"   ğŸŒ HFé•œåƒ: {summary['hf_endpoint']}")
    if summary['debug']:
        print("   ğŸ› è°ƒè¯•æ¨¡å¼: å·²å¯ç”¨")
